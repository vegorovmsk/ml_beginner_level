{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "name": "homework_classification-1_les-6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vegorovmsk/ml_beginner_level/blob/master/homework_classification_1_les_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00L7jHy7MKoq"
      },
      "source": [
        "# Урок 6. Наивный байесовский классификатор\n",
        "\n",
        "В уроке мы подробно рассмотрели, как работает наивный байесовский классификатор, на примере частотной таблицы. Такие данные на практике встречаются довольно редко (если вы не работаете с классификацией текстов), поэтому сейчас предлагаем самостоятельно разобрать принцип работы гауссовского наивного Байеса, который можно встретить чаще остальных."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3ThYs4uMKos"
      },
      "source": [
        "### 1.\n",
        "Посмотрите, что включает в себя новый датасет Wine, где собраны результаты химического анализа вин, выращенных в одном регионе Италии тремя различными культиваторами. В наборе каждый из объектов имеет 13 числовых признаков.\n",
        "\n",
        "Изучите попарные графики признаков (в уроках мы рассматривали их с помощью функции pd.plotting.scatter_matrix() ) и выберите такие два признака, используя которые, на ваш взгляд, можно будет лучше всего разделить данные по трем классам. Помните о том, что модель гауссовского наивного Байеса использует для предсказаний среднее и разброс значений признаков относительно среднего, поэтому вероятнее всего, лучшими признаками будут те, значения которых на графике разбросаны примерно одинаково от среднего значения, но как можно меньше накладываются на признаки других классов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NY-OU3vSMKot"
      },
      "source": [
        "*Примечание: для наглядности в параметрах функции построения графиков примените figsize=(25, 25) - это позволит отобразить график достаточного размера для того, чтобы его изучить.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxhahZySMKou"
      },
      "source": [
        "from sklearn.datasets import load_wine\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlPv8zRmMKo0"
      },
      "source": [
        "### YOUR CODE HERE ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GR6f2nC2MKo4"
      },
      "source": [
        "### 2.\n",
        "Разбейте данные на тренировочный и тестовый датасеты (при разбиении используйте параметр random_state=17 для воспроизводимости результатов) и постройте модель на двух выбранных признаках. Используя встроенную функцию *score()*, проверьте точность работы модели. Если score() меньше 0.88..., выберите по графику другие два признака и постройте модель на них. Укажите номера признаков, которые вы использовали (помните, что индекс массива признаков начинается с 0)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2ODKt__MKo6"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNWaSWhWMKo_"
      },
      "source": [
        "nb = GaussianNB()\n",
        "\n",
        "### YOUR CODE HERE ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKWxFrJpMKpE"
      },
      "source": [
        "У модели GaussianNB есть метод predict_proba(test), который возвращает вероятности принадлежности каждого объекта из *test* к каждому из классов. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4uRVRMUMKpF"
      },
      "source": [
        "### 3.\n",
        "Еще раз обучите модель на признаках с номерами 11, 12, предварительно снова разбив данные на тренировочные и тестовые (с random_state=17). С помощью функции predict_proba() посмотрите, какие вероятности были вычислены для каждого из классов, и выведите эти вероятности для объекта x_test[0]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5kaFsneMKpF"
      },
      "source": [
        "### YOUR CODE HERE ###"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}