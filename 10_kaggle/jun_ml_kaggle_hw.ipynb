{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pxO3HAEKXbaD"
   },
   "source": [
    "# Kaggle\n",
    "\n",
    "В этом домашнем задании вам нужно будет построить модель для данных соревнования [Titanic на Kaggle](https://www.kaggle.com/c/titanic/overview), сформировать файл с предсказаниями для тестовых данных и отправить его на проверку.\n",
    "\n",
    "В практике из урока вашим заданием было разобрать одно из самых популярных ядер для соревнования Titanic и преобразовать его таким образом, чтобы остались только преобразование данных и графики.\n",
    "\n",
    "Соответственно, сейчас ваше ядро должно выглядеть таким образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "LX1TF3s4XbaK"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "rDjGyaytXbaZ",
    "outputId": "023f27a4-9cb6-4817-ed12-5464062f5116"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in the train and test datasets\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# Store our passenger ID for easy access\n",
    "PassengerId = test['PassengerId']\n",
    "\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "g2dvsncuXban"
   },
   "outputs": [],
   "source": [
    "full_data = [train, test]\n",
    "\n",
    "# Добавил для стабильности результатов заполнения пропущенных значений возраста\n",
    "np.random.seed(17)\n",
    "\n",
    "# Gives the length of the name\n",
    "train['Name_length'] = train['Name'].apply(len)\n",
    "test['Name_length'] = test['Name'].apply(len)\n",
    "# Feature that tells whether a passenger had a cabin on the Titanic\n",
    "train['Has_Cabin'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
    "test['Has_Cabin'] = test[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
    "\n",
    "# Create new feature FamilySize as a combination of SibSp and Parch\n",
    "for dataset in full_data:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "# Create new feature IsAlone from FamilySize\n",
    "for dataset in full_data:\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "# Remove all NULLS in the Embarked column\n",
    "for dataset in full_data:\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna('S')\n",
    "# Remove all NULLS in the Fare column and create a new feature CategoricalFare\n",
    "for dataset in full_data:\n",
    "    dataset['Fare'] = dataset['Fare'].fillna(train['Fare'].median())\n",
    "train['CategoricalFare'] = pd.qcut(train['Fare'], 4)\n",
    "# Create a New feature CategoricalAge\n",
    "for dataset in full_data:\n",
    "    age_avg = dataset['Age'].mean()\n",
    "    age_std = dataset['Age'].std()\n",
    "    age_null_count = dataset['Age'].isnull().sum()\n",
    "    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n",
    "    dataset['Age'][np.isnan(dataset['Age'])] = age_null_random_list\n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "train['CategoricalAge'] = pd.cut(train['Age'], 5)\n",
    "# Define function to extract titles from passenger names\n",
    "def get_title(name):\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    # If the title exists, extract and return it.\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "# Create a new feature Title, containing the titles of passenger names\n",
    "for dataset in full_data:\n",
    "    dataset['Title'] = dataset['Name'].apply(get_title)\n",
    "# Group all non-common titles into one single grouping \"Rare\"\n",
    "for dataset in full_data:\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "for dataset in full_data:\n",
    "    # Mapping Sex\n",
    "    dataset['Sex'] = dataset['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
    "    \n",
    "    # Mapping titles\n",
    "    title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)\n",
    "    \n",
    "    # Mapping Embarked\n",
    "    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
    "    \n",
    "    # Mapping Fare\n",
    "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "    \n",
    "    # Mapping Age\n",
    "    dataset.loc[ dataset['Age'] <= 16, 'Age'] \t\t\t\t\t       = 0\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "    dataset.loc[ dataset['Age'] > 64, 'Age'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "6BA6Gkj-Xba0"
   },
   "outputs": [],
   "source": [
    "# Feature selection\n",
    "drop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp']\n",
    "train = train.drop(drop_elements, axis = 1)\n",
    "train = train.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\n",
    "test  = test.drop(drop_elements, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "I2DXDDnCXba8",
    "outputId": "c3223475-827e-4e1b-a029-844306793f13"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Name_length</th>\n",
       "      <th>Has_Cabin</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex  Age  Parch  Fare  Embarked  Name_length  Has_Cabin  \\\n",
       "0         0       3    1    1      0     0         0           23          0   \n",
       "1         1       1    0    2      0     3         1           51          1   \n",
       "2         1       3    0    1      0     1         0           22          0   \n",
       "\n",
       "   FamilySize  IsAlone  Title  \n",
       "0           2        0      1  \n",
       "1           2        0      3  \n",
       "2           1        1      2  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Jtrbw694XbbG",
    "outputId": "4cc29f9e-1332-473b-8bb9-f7d32965360c"
   },
   "outputs": [],
   "source": [
    "# colormap = plt.cm.RdBu\n",
    "# plt.figure(figsize=(14,12))\n",
    "# plt.title('Pearson Correlation of Features', y=1.05, size=15)\n",
    "# sns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \n",
    "#             square=True, cmap=colormap, linecolor='white', annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "cLcwBZRXXbbR",
    "outputId": "ea2c24a0-1b63-4426-a533-57adb83eb9be"
   },
   "outputs": [],
   "source": [
    "# g = sns.pairplot(train[[u'Survived', u'Pclass', u'Sex', u'Age', u'Parch', u'Fare', \n",
    "#                         u'Embarked', u'FamilySize', u'Title']], \n",
    "#                  hue='Survived', palette = 'seismic', size=1.2, plot_kws=dict(s=10))\n",
    "# g.set(xticklabels=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "betqXe7KXbbb"
   },
   "source": [
    "Итак, у нас получились два датасета с новыми признаками. Теперь приступим к построению модели.\n",
    "\n",
    "### Построение модели\n",
    "\n",
    "### 1.\n",
    "\n",
    "Воспользуйтесь вашим алгоритмом стекинга из предыдущего домашнего задания. В качестве базовых алгоритмов используйте RandomForestClassifier, SVC, GradientBoostingClassifier и LogisticRegression; в качестве мета-алгоритма - XGBoost.\n",
    "\n",
    "Разделите данные train на тренировочную и валидационную выборки с random_state=17 и параметром разбиения test_size=.3 (в качестве целевой переменной возьмите столбец Survived, а в качестве признаков - все остальные столбцы).\n",
    "\n",
    "Ниже приведены параметры для каждого из базовых алгоритмов, которые необходимо настроить на 5-кратной кросс-валидации с помощью GridSearchCV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "_u1wEHlnXbbe"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import (GridSearchCV,\n",
    "                                     train_test_split,\n",
    "                                     StratifiedKFold)\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# параметры базовых алгоритмов\n",
    "gbc_params = {'learning_rate': np.arange(0.1, 0.6, 0.1), \n",
    "              'random_state': [17]} # GradientBoostingClassifier\n",
    "\n",
    "rfc_params = {'n_estimators': range(10, 100, 10), # RandomForestClassifier\n",
    "              'min_samples_leaf': range(1, 5), \n",
    "              'random_state': [17]}\n",
    "\n",
    "svc_params = {'kernel': ['linear', 'rbf'], # SVC\n",
    "              'C': np.arange(0.1, 1, 0.2), \n",
    "              'random_state': [17]}\n",
    "\n",
    "lr_params = {'C': np.arange(0.5, 1, 0.1), \n",
    "             'random_state': [17]}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, random_state=17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P-LUQKa9Xbbk"
   },
   "source": [
    "### 2.\n",
    "1. Определите объект GridSearchCV для всех приведенных параметров каждого алгоритма (в гиперпараметрах алгоритма при его определении, если возможно, укажите random_state=17). Параметр cv устанавливайте равным skf.\n",
    "\n",
    "2. Обучите каждый из объектов из 1-го пункта на получившейся при разбиении тренировочной выборке. Выведите лучшее сочетание параметров для каждого из алгоритмов.\n",
    "\n",
    "3. Для каждого обученного алгоритма получите предсказания на валидационных данных и выведите метрику качества, которая соответствует метрике оценки соревнования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "so002-PDXbbm"
   },
   "outputs": [],
   "source": [
    "X = train.drop(['Survived'], axis=1)\n",
    "y = train[['Survived']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=17, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'gbc': GradientBoostingClassifier(random_state=17), \n",
    "          'rfc': RandomForestClassifier(random_state=17), \n",
    "          'svc': SVC(random_state=17), \n",
    "          'lr': LogisticRegression(random_state=17)}\n",
    "\n",
    "params = [gbc_params, rfc_params, svc_params, lr_params]\n",
    "\n",
    "best_params = []\n",
    "best_models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbc -- 0.7611940298507462\n",
      "rfc -- 0.7835820895522388\n",
      "svc -- 0.7873134328358209\n",
      "lr -- 0.7947761194029851\n"
     ]
    }
   ],
   "source": [
    "# Соберем цикл для формирования моделей с лучшими параметрами\n",
    "# и создания матрицы метапризнаков\n",
    "\n",
    "meta_mtrx = np.empty((X_test.shape[0], len(models)))\n",
    "\n",
    "for n, (name, model) in enumerate(models.items()):\n",
    "    clf = GridSearchCV(estimator=model, param_grid=params[n], cv=skf).fit(X_train, y_train)\n",
    "    best_models.append(clf)\n",
    "    best_params.append(clf.best_params_)\n",
    "    meta_mtrx[:, n] = clf.predict(X_test)\n",
    "    print(f\"{str(name)[:3]} -- {clf.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IrcXh11rXbbr"
   },
   "source": [
    "### 3.\n",
    "С помощью GridSearchCV и указанных ниже параметров настройте мета-алгоритм на мета-признаках (используйте 5-кратную валидацию и random_state=17 при определении алгоритма). Матрицу метапризнаков получите из предсказаний, полученных в предыдущем пункте на валидационных данных базовыми алгоритмами. Выведите лучшие параметры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "klDpMpPAXbbu"
   },
   "outputs": [],
   "source": [
    "xgb_params = {'n_estimators': range(10, 100, 5),\n",
    "              'eta': np.arange(0.1, 1., .1),\n",
    "              'min_child_weight': range(1, 10, 1),\n",
    "              'subsample': np.arange(0.1, 1., 0.2),\n",
    "              'random_state': [17]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Aw3nUCsCXbb2"
   },
   "outputs": [],
   "source": [
    "clf_xgb = GridSearchCV(estimator=XGBClassifier(), param_grid=xgb_params, cv=skf)\n",
    "clf_xgb.fit(meta_mtrx, y_test)\n",
    "xgb_best_params = clf_xgb.best_params_\n",
    "xgb_best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZdPk3Y6TXbb8"
   },
   "source": [
    "### 4.\n",
    "На основе алгоритма из предыдущего домашнего задания постройте стекинг (используйте 5-кратную кросс-валидацию) для всех моделей с наилучшими подобранными параметрами. В качестве тренировочных данных используйте весь датасет train.csv, а в качестве тестовых - весь датасет test.csv. Сделайте прогноз мета-алгоритма для test.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X4yLqrjMXbb_"
   },
   "outputs": [],
   "source": [
    "def stacking(models, meta_alg, data_train, targets_train, data_test, targets_test=None, random_state=17, test_size=None, cv=5):\n",
    "    \n",
    "    if test_size is None:\n",
    "        meta_mtrx = np.empty((data_train.shape[0], len(models)))\n",
    "        \n",
    "        for n, model in enumerate(models):\n",
    "            meta_mtrx[:, n] = cross_val_predict(model, data_train, targets_train, cv=cv, method='predict')    \n",
    "            model.fit(data_train, targets_train)\n",
    "        \n",
    "        meta_model = meta_alg.fit(meta_mtrx, targets_train)\n",
    "        \n",
    "        meta_mtrx_test = np.empty((data_test.shape[0], len(models)))\n",
    "        \n",
    "        for n, model in enumerate(models):\n",
    "            meta_mtrx_test[:, n] =  model.predict(data_test)\n",
    "        \n",
    "        meta_predicted = meta_model.predict(meta_mtrx_test)\n",
    "        \n",
    "        if targets_test is not None:\n",
    "            print(f\"accuracy: {accuracy_score(targets_test, meta_predicted)}\")    \n",
    "        \n",
    "    \n",
    "    elif test_size > 0 and test_size < 1:\n",
    "        train, valid, train_true, valid_true = train_test_split(data_train,\n",
    "                                                                targets_train,\n",
    "                                                                test_size=test_size,\n",
    "                                                                random_state=random_state)\n",
    "        meta_mtrx = np.empty((valid.shape[0], len(models)))\n",
    "        \n",
    "        for n, model in enumerate(models):\n",
    "            model.fit(train, train_true)\n",
    "            meta_mtrx[:, n] = model.predict(valid)\n",
    "            \n",
    "        meta_model = meta_alg.fit(meta_mtrx, valid_true)\n",
    "        \n",
    "        meta_mtrx_test = np.empty((data_test.shape[0], len(models)))\n",
    "        \n",
    "        for n, model in enumerate(models):\n",
    "            meta_mtrx_test[:, n] =  model.predict(data_test)\n",
    "            \n",
    "        meta_predicted = meta_model.predict(meta_mtrx_test)\n",
    "        \n",
    "        if targets_test is not None:\n",
    "            print(f\"accuracy: {accuracy_score(targets_test, meta_predicted)}\")\n",
    "        \n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"test_size must be between 0 and 1\")\n",
    "    \n",
    "    return meta_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = stacking(best_models, clf_xgb, X, y, test, targets_test=PassengerId, random_state=17, test_size=0.2, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9lhat2YqXbcD"
   },
   "source": [
    "### 5.\n",
    "С помощью нижеприведенной функции сформируйте файл посылки для соревнования и отправьте на Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uOND9iBIXbcF"
   },
   "outputs": [],
   "source": [
    "def write_to_submission_file(predictions, PassengerID, out_file='Submission.csv', columns=['PassengerID', 'Survived']):\n",
    "    predicted_df = pd.DataFrame(np.array([PassengerId, predictions]).T, columns=columns)\n",
    "    predicted_df.to_csv(out_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TXFbXmqZXbcJ"
   },
   "outputs": [],
   "source": [
    "write_to_submission_file(predictions, PassengerId, out_file='Submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8lLSV_sHXbcN"
   },
   "source": [
    "### 6.\n",
    "Каков результат score, полученного на соревновании?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4VEP0qzXXbcO"
   },
   "source": [
    "Ваш ответ: 0.77751"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "jun_ml_kaggle_hw.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
